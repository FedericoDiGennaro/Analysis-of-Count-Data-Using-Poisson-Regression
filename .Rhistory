data <- read_excel("data/data.xlsx")
knitr::opts_chunk$set(
echo       = FALSE,    # Do not print code
warning    = FALSE,    # Suppress warnings
message    = FALSE,    # Suppress messages
fig.align  = "center", # Center figures
fig.width  = 2.7,      # Good standard figure width for single-panel figures
fig.height = 2.4,       # Good standard figure height for single-panel figures
fig.pos = "ht",
out.extra = ""
)
# Generate some example data
set.seed(0)
y <- data[3]
# Plot histogram of observed y and Poisson distribution
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
# Plot histogram of observed y
hist(observed_y, breaks = 10, col = "skyblue", border = "black", main = "Histogram of Observed y",
xlab = "Value", ylab = "Frequency")
# Generate some example data
set.seed(0)
y <- data[3]
# Plot histogram of observed y and Poisson distribution
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
# Plot histogram of observed y
hist(y, breaks = 10, col = "skyblue", border = "black", main = "Histogram of Observed y",
xlab = "Value", ylab = "Frequency")
# Generate some example data
set.seed(0)
y <- data[3]
# Plot histogram of observed y and Poisson distribution
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
# Plot histogram of observed y
hist(y$Apprentices, breaks = 10, col = "skyblue", border = "black", main = "Histogram of Observed y",
xlab = "Value", ylab = "Frequency")
# Plot histogram of Poisson distribution
lambda <- mean(y$Apprentices)
x <- 0:max(y$Apprentices)
poisson_probs <- dpois(x, lambda)
barplot(poisson_probs, names.arg = x, col = "lightgreen", border = "black",
main = "Histogram of Poisson Distribution", xlab = "Value", ylab = "Probability")
# define dependent
#hist(y$Apprentices, breaks=seq(0,250,10), main="Histogram of the outcome variable", #xlab = "Number of Apprentices", ylab = "Frequency")
# Generate some example data
set.seed(0)
y <- data[3]
# Plot histogram of observed y and Poisson distribution
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
# Plot histogram of observed y
hist(y$Apprentices, breaks=seq(0,250,10), col = "skyblue", border = "black", main = "Histogram of Observed y",
xlab = "Value", ylab = "Frequency")
# Plot histogram of Poisson distribution
lambda <- mean(y$Apprentices)
x <- 0:max(y$Apprentices)
poisson_probs <- dpois(x, lambda)
barplot(poisson_probs, names.arg = x, col = "lightgreen", border = "black",
main = "Histogram of Poisson Distribution", xlab = "Value", ylab = "Probability")
# define dependent
#hist(y$Apprentices, breaks=seq(0,250,10), main="Histogram of the outcome variable", #xlab = "Number of Apprentices", ylab = "Frequency")
# load packages -----------------------------------------------------------
library(ggplot2)
library(tidyverse)
library(GGally)
library(readxl)
library(MASS) # for BOXCOX
library(car) # for VIF
library(performance) # for nicer multicollinearity plot
library(jtools)
library(sandwich)
library(goodness-of-fit)
library(pscl)
library(AER)
# load data ---------------------------------------------------------------
rm(list = ls())
data <- read_excel("data/data.xlsx")
glimpse(data)
# define regressors
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
# define dependent
y <- data[3]
# check presence of missing values
print(c('is there any missing value? ', any(is.na(data))))
# univariate numerical analysis for numeric variables
summary(X)
var(X[-4])
ggpairs(X)
# in order to check the differences in distribution due to difference in the
# union_shop variable, use this: (DISAGGREGATE DATA wrt Union_shop)
# Create the ggpairs plot
plot <- ggpairs(X, aes(color = Direction, alpha = .5),
lower = list(continuous = 'smooth'), legend = 1) +
theme(legend.position = "bottom", text = element_text(size = 12),
axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 8))
# Remove alpha from the legend
plot <- plot +
scale_alpha_identity(guide = "none")
# Display the plot
print(plot)
# Create the ggpairs plot with histogram
hist(y$Apprentices, breaks=seq(0,250,10))
hist(y$Apprentices, breaks=seq(0,250,10), xlab = "Number of Apprentices", ylab = "Frequency")
mean(y$Apprentices)
var(y$Apprentices)
par(mfrow=c(1,1))
boxplot(X[-4], las = 2, col = c("red", "steelblue", "yellow"), ylab ="(%)")
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = poisson(link = "log"))
summary(poisson.model)
dispersion_test(poisson.model)
qpoisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = quasipoisson())
summary(qpoisson.model)
qpoisson.model1<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = quasipoisson())
summary(qpoisson.model1)
install.packages("AICcmodavg")
library(AICcmodavg)
# load data ---------------------------------------------------------------
rm(list = ls())
data <- read_excel("data/data.xlsx")
glimpse(data)
# define regressors
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
# define dependent
y <- data[3]
# check presence of missing values
print(c('is there any missing value? ', any(is.na(data))))
# univariate numerical analysis for numeric variables
summary(X)
var(X[-4])
ggpairs(X)
# in order to check the differences in distribution due to difference in the
# union_shop variable, use this: (DISAGGREGATE DATA wrt Union_shop)
# Create the ggpairs plot
plot <- ggpairs(X, aes(color = Direction, alpha = .5),
lower = list(continuous = 'smooth'), legend = 1) +
theme(legend.position = "bottom", text = element_text(size = 12),
axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 8))
# Remove alpha from the legend
plot <- plot +
scale_alpha_identity(guide = "none")
# Display the plot
print(plot)
# Create the ggpairs plot with histogram
hist(y$Apprentices, breaks=seq(0,250,10))
hist(y$Apprentices, breaks=seq(0,250,10), xlab = "Number of Apprentices", ylab = "Frequency")
mean(y$Apprentices)
var(y$Apprentices)
par(mfrow=c(1,1))
boxplot(X[-4], las = 2, col = c("red", "steelblue", "yellow"), ylab ="(%)")
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = poisson(link = "log"))
summary(poisson.model)
dispersion_test(poisson.model)
# Calculate the Pearson chi-square statistic
pearson_chi_sq <- sum(pearson_resid^2)
# Obtain the residual degrees of freedom
df_resid <- df.residual(poisson.model)
# Estimate the dispersion parameter
dispersion <- pearson_chi_sq / df_resid
# Print the estimated dispersion parameter
print(dispersion)
epiDisplay::poisgof(poisson.model)
# MODEL 2: removing the outlier ---------------------------------------------------------------------
rm(list = ls())
data <- read_excel("data/data2.xlsx")
glimpse(data)
# define regressors
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
# define dependent
y <- data[3]
hist(y$Apprentices, breaks=seq(0,250,10))
mean(y$Apprentices)
var(y$Apprentices)
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = poisson(link = "log"),
control = glm.control(maxit = 1000))
summary(poisson.model)
dispersiontest(poisson.model)
qpoisson.model1<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(qpoisson.model1)
with(poisson.model, cbind(res.deviance = deviance, df = df.residual,
p = pchisq(deviance, df.residual, lower.tail=FALSE)))
poisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(poisson.model2)
# MODEL 3: log of population and distance ---------------------------------------------------------------------
data$Distance = log(data$Distance)
data$Population = log(data$Population)
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = poisson(link = "log"),
control = glm.control(maxit = 1000))
summary(poisson.model)
poisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(poisson.model2)
QIC(poisson.model1, poisson.model2)
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = poisson(link = "log"),
control = glm.control(maxit = 1000))
summary(poisson.model)
poisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(poisson.model2)
# MODEL 2: removing the outlier ---------------------------------------------------------------------
rm(list = ls())
data <- read_excel("data/data2.xlsx")
glimpse(data)
# define regressors
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
# define dependent
y <- data[3]
hist(y$Apprentices, breaks=seq(0,250,10))
mean(y$Apprentices)
var(y$Apprentices)
# MODEL 3: log of population and distance ---------------------------------------------------------------------
data$Distance = log(data$Distance)
data$Population = log(data$Population)
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = poisson(link = "log"),
control = glm.control(maxit = 1000))
summary(poisson.model)
dispersiontest(poisson.model)
qpoisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(qpoisson.model2)
# MODEL 4: interactions ---------------------------------------------------------------------
ggpairs(X)
#with the log
rm(list = ls())
data <- read_excel("data/data2.xlsx")
glimpse(data)
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
y <- data[3]
data$Distance = log(data$Distance)
data$Population = log(data$Population)
qpoisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(qpoisson.model2)
poisson.model3<-glm(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data, family = poisson(link="log"))
summary(poisson.model3)
dispersiontest(poisson.model3)
qpoisson.model3<-glm(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data, family = quasipoisson())
summary(qpoisson.model3)
drop_in_dev <- anova(qpoisson.model2, qpoisson.model3, test = "F")
summary(drop_in_dev)
drop_in_dev
# load packages -----------------------------------------------------------
library(ggplot2)
library(tidyverse)
library(GGally)
library(readxl)
library(MASS) # for BOXCOX
library(car) # for VIF
library(performance) # for nicer multicollinearity plot
library(jtools)
library(sandwich)
library(goodness-of-fit)
library(pscl)
library(AER)
library(AICcmodavg)
# load data ---------------------------------------------------------------
rm(list = ls())
data <- read_excel("data/data.xlsx")
glimpse(data)
# define regressors
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
# define dependent
y <- data[3]
# check presence of missing values
print(c('is there any missing value? ', any(is.na(data))))
# univariate numerical analysis for numeric variables
summary(X)
var(X[-4])
ggpairs(X)
# in order to check the differences in distribution due to difference in the
# union_shop variable, use this: (DISAGGREGATE DATA wrt Union_shop)
# Create the ggpairs plot
plot <- ggpairs(X, aes(color = Direction, alpha = .5),
lower = list(continuous = 'smooth'), legend = 1) +
theme(legend.position = "bottom", text = element_text(size = 12),
axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 8))
# Remove alpha from the legend
plot <- plot +
scale_alpha_identity(guide = "none")
# Display the plot
print(plot)
# Create the ggpairs plot with histogram
hist(y$Apprentices, breaks=seq(0,250,10))
hist(y$Apprentices, breaks=seq(0,250,10), xlab = "Number of Apprentices", ylab = "Frequency")
mean(y$Apprentices)
var(y$Apprentices)
par(mfrow=c(1,1))
boxplot(X[-4], las = 2, col = c("red", "steelblue", "yellow"), ylab ="(%)")
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = poisson(link = "log"))
summary(poisson.model)
dispersion_test(poisson.model)
hist(y$Apprentices, breaks=seq(0,250,10))
mean(y$Apprentices)
var(y$Apprentices)
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = poisson(link = "log"),
control = glm.control(maxit = 1000))
summary(poisson.model)
dispersiontest(poisson.model)
qpoisson.model1<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(qpoisson.model1)
with(poisson.model, cbind(res.deviance = deviance, df = df.residual,
p = pchisq(deviance, df.residual, lower.tail=FALSE)))
poisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(poisson.model2)
# MODEL 3: log of population and distance ---------------------------------------------------------------------
data$Distance = log(data$Distance)
data$Population = log(data$Population)
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = poisson(link = "log"),
control = glm.control(maxit = 1000))
summary(poisson.model)
dispersiontest(poisson.model)
qpoisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(qpoisson.model2)
# MODEL 4: interactions ---------------------------------------------------------------------
ggpairs(X)
poisson.model3<-glm(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data, family = poisson(link="log"))
summary(poisson.model3)
dispersiontest(poisson.model3)
qpoisson.model3<-glm(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data, family = quasipoisson())
summary(qpoisson.model3)
#F test to compare two quasi-poisson models (NESTED, H0: reduced model is sufficient)
drop_in_dev <- anova(qpoisson.model2, qpoisson.model3, test = "F")
drop_in_dev
nb.model<-glm.nb(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data)
summary(nb.model)
#MODEL ASSESSMENT
predicted <- predict(qpoisson.model3, type = "link")
observed <- y$Apprentices
plot(predicted, observed, xlab = "Predicted Linear Predictor", ylab = "Observed Log Count")
abline(lm(observed ~ predicted), col = "red")
residuals <- residuals(qpoisson.model3)
# Create a scatterplot of residuals against each other
plot(residuals[-length(residuals)], residuals[-1], xlab = "Residuals (i)", ylab = "Residuals (i+1)")
install.packages("performance")
install.packages("performance")
# load packages -----------------------------------------------------------
library(ggplot2)
library(tidyverse)
library(GGally)
library(readxl)
library(MASS) # for BOXCOX
library(car) # for VIF
library(performance) # for nicer multicollinearity plot
library(jtools)
library(sandwich)
library(goodness-of-fit)
library(pscl)
library(AER)
library(AICcmodavg)
library(performance)
# load data ---------------------------------------------------------------
rm(list = ls())
data <- read_excel("data/data.xlsx")
glimpse(data)
# define regressors
data$Direction <- as.factor(data$Direction)
X <- data[-c(1,3)]
# define dependent
y <- data[3]
# check presence of missing values
print(c('is there any missing value? ', any(is.na(data))))
# univariate numerical analysis for numeric variables
summary(X)
var(X[-4])
ggpairs(X)
# in order to check the differences in distribution due to difference in the
# union_shop variable, use this: (DISAGGREGATE DATA wrt Union_shop)
# Create the ggpairs plot
plot <- ggpairs(X, aes(color = Direction, alpha = .5),
lower = list(continuous = 'smooth'), legend = 1) +
theme(legend.position = "bottom", text = element_text(size = 12),
axis.text.x = element_text(size = 8), axis.text.y = element_text(size = 8))
# Remove alpha from the legend
plot <- plot +
scale_alpha_identity(guide = "none")
# Display the plot
print(plot)
# Create the ggpairs plot with histogram
hist(y$Apprentices, breaks=seq(0,250,10))
hist(y$Apprentices, breaks=seq(0,250,10), xlab = "Number of Apprentices", ylab = "Frequency")
mean(y$Apprentices)
var(y$Apprentices)
par(mfrow=c(1,1))
boxplot(X[-4], las = 2, col = c("red", "steelblue", "yellow"), ylab ="(%)")
poisson.model<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction , data, family = poisson(link = "log"))
summary(poisson.model)
dispersion_test(poisson.model)
performance::check_model(mod1)
performance::check_model(qpoisson.model3)
qpoisson.model2<-glm(Apprentices ~ Distance + Population + Degree_Urb
+ Direction, data , family = quasipoisson(),
control = glm.control(maxit = 1000))
summary(qpoisson.model2)
# MODEL 4: interactions ---------------------------------------------------------------------
ggpairs(X)
poisson.model3<-glm(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data, family = poisson(link="log"))
summary(poisson.model3)
dispersiontest(poisson.model3)
qpoisson.model3<-glm(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data, family = quasipoisson())
summary(qpoisson.model3)
#F test to compare two quasi-poisson models (NESTED, H0: reduced model is sufficient)
drop_in_dev <- anova(qpoisson.model2, qpoisson.model3, test = "F")
drop_in_dev
nb.model<-glm.nb(Apprentices ~ (Distance + Population + Degree_Urb
+ Direction)^2 , data)
summary(nb.model)
#1) linearity with log count
predicted <- predict(qpoisson.model3, type = "link")
observed <- y$Apprentices
plot(predicted, observed, xlab = "Predicted Linear Predictor", ylab = "Observed Log Count")
abline(lm(observed ~ predicted), col = "red")
residuals <- residuals(qpoisson.model3)
# Create a scatterplot of residuals against each other
plot(residuals[-length(residuals)], residuals[-1], xlab = "Residuals (i)", ylab = "Residuals (i+1)")
performance::check_model(qpoisson.model3)
performance::check_model(qpoisson.model3)
install.packages("randomForest")
performance::check_normality(qpoisson.model3)
performance::check_heteroscedasticity(qpoisson.model3)
performance::check_outliers(qpoisson.model3)
performance::check_distribution(qpoisson.model3)
performance::check_overdispersion(qpoisson.model3)
performance::check_zeroinflation(qpoisson.model3)
performance::check_model(qpoisson.model3)
check_model(qpoisson.model3, plot = FALSE)
performance::check_model(qpoisson.model3, plot = FALSE)
performance::check_model(qpoisson.model2, plot = FALSE)
plot(check_overdispersion(qpoisson.model3))
plot(check_zeroinflation(qpoisson.model3))
plot(check_distribution(qpoisson.model3))
plot(check_outliers(qpoisson.model3))
plot(check_normality(qpoisson.model3))
plot(check_heteroscedasticity(qpoisson.model3))
performance::check_model(qpoisson.model2, plot = FALSE)
plor(check_autocorrelation(qpoisson.model3))
plot(check_autocorrelation(qpoisson.model3))
check_autocorrelation(qpoisson.model3)
check_zeroinflation(qpoisson.model3)
par(mfrow = c(2,2))
# Plot normality check
plot(check_normality(qpoisson.model3))
# Plot outliers check
plot(check_outliers(qpoisson.model3))
# Plot distribution check
plot(check_distribution(qpoisson.model3))
# Plot overdispersion check
plot(check_overdispersion(qpoisson.model3))
# Plot normality check
plot(qqnorm(resid(qpoisson.model3)), main = "Normal Q-Q Plot")
# Plot outliers check
plot(resid(qpoisson.model3), main = "Residual Plot")
# Plot distribution check
plot(fitted(qpoisson.model3), residuals(qpoisson.model3), main = "Fitted vs Residuals")
# Plot overdispersion check
plot(resid(qpoisson.model3)^2 ~ fitted(qpoisson.model3), main = "Scale-Location Plot")
par(mfrow = c(2,2))
# Plot normality check
plot(check_normality(qpoisson.model3))
par(mfrow = c(2,2))
# Plot outliers check
plot(check_outliers(qpoisson.model3))
# Plot normality check
plot(check_normality(qpoisson.model3))
check_independence(qpoisson.model3)
# Extract the residuals
my_resid <- resid(qpoisson.model3, type = "pearson")
# Plot the residuals against the fitted values
plot(qpoisson.model3$fitted.values, my_resid)
par(mfrow = c(1,1))
# Extract the residuals
my_resid <- resid(qpoisson.model3, type = "pearson")
# Plot the residuals against the fitted values
plot(qpoisson.model3$fitted.values, my_resid)
plot(qpoisson.model3)
plot(qpoisson.model3)[1]
plot(qpoisson.model3, which=1)
